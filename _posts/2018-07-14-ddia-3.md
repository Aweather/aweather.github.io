---
layout: single
title: "Notes on Designing Data-Intensive Applications: Chapter 3 Storage and Retrieval"
date: 2018-08-01 23:41 -0700
categories: "software engineering"
mathjax: true
---

## Introduction
- Databases fundamentally does two things: Store data and retrieve the stored data.
- Chapter 3 discusses how data model and queries are interpreted by databases.
- Understanding under-the-hood details can help us pick the right solution and tune the performance.
- We'll first look at two types of storage engines: log-structured and page-oriented storage engines.

## Data Structures That Power Your Database
- Many databases internally uses a log, which is a append-only data file.
- To retrieve data efficiently, we need an index, which is an additional structure derived from primary data and only affects performance of queries.
- Well-chosen indexes speed up queries but slow down writes. Therefore, databases don't index everything by default and requires developers to use knowledge of query pattens to choose index manually.

### Hash Indexes
- Hash Indexes are for key-value data and are similar to a dictionary, which is usually implemented as a hash map (hash table).
- If the database writes only append new entires to a file, the hash table can simply store key to byte offset in the data file. The hash table (with keys) has to fit into memory for quick look up performance, but the values don't have to fit into memory.
- To avoid the disk run out of space, a good solution is to break logs into segments and perform compaction (remove duplicate keys). Further, file segments can be merged while performing compaction. We can use a background thread to perform merging and compaction and switch our read request to the newly created segment when they are read. Afterwards, old segments can be deleted.
- There are a few details for a real implementation of the idea above
  - Use bytes instead of CSV
  - Deletes are adding a special log entry to the data file (tombstone) and the data will be removed during merging and compaction.
  - Index will need to be snapshotted for fast crash recovery (compared to re-indexing).
  - Checksums are required for detecting partially written records.
  - Writes has to strictly be in sequential order. Many implementation choose to have one writer thread.
- Why append-only logs are good
  - Sequential writes are much faster than random writes, especially on magnetic spinning-disk hard drives and to some extent SSDs.
  - Concurrency and crash recovery are much simpler if segment files are append-only or immutable.
  - Merging old segments avoids data fragmentation.
- What are the limitations of hash table indexes?
  - Hash table must fit into memory. If there are too many keys, it will not fit.
  - Range queries are not efficient.


### SSTables and LSM-Trees
- The Sorted String Table (SSTable) requires each segment file to be sorted by key. It has the following advantages.
  - Merging segments is simple and efficient.
  - We no longer require offset of every single key for efficient lookup. One key for every few kilobytes of segment file is usually sufficient.
  - Since reading requires a linear scan in between indexed keys, we can group those records and compress them to save storage or I/O bandwidth.

#### Constructing and maintaining SSTables
- While maintaining a sorted structure on disk is possible (B-Trees), red-black trees or AVL trees can be used to keep logs sorted in memory.
The flow is as follows:
  - When a write comes in, insert the entry to the in-memory data structure (sometimes called *memtable*).
  - When memtable gets bigger than some threshold (a few megabytes), create a new memtable to handle new writes, and write the old memtable to disk.
  - For reads, first try to find the key in memtable, and in the latest segment, and in the second last segment...
  - Occasionally, run a merging and compaction process to combine segment files.
- The issue with this scheme is that in-memory data will be lost if the database crashes. We can keep a separate unsorted log for recovery and this log can be discarded whenever a memtable is dumped to disk.
- This indexing structure is named Log-Structure Merge-Tree (LSM-Tree).

#### Making an LSM-tree out of SSTables
- The algorithm here is used by LevelDB and RocksDB, which are key-value storage libraries to be used in other applications. Similar storage systems are also used in Cassandra and HBase.
- Systems that uses the principle of merging and compacting sorted files are often called LSM systems.

#### Performance optimizations
- A look up can take a long time if the entry does not exist in any of the memtable. Bloom filters can be used to solve this issue.
- There are two major strategies to determine the order and timing of merging and compaction: size-tiered (HBase, Cassandra) and level compaction (LevelDB, RockDB, Cassandra).
  - Size-tiered: newer and smaller SSTables are merged into larger ones.
  - Level: The key range is split up into several SSTables and older data is moved to separate "levels," which allows compaction to proceed more incrementally and use less disk space.

- LSM-tree: Write throughput is high. Can efficiently index data much larger than memory.

### B-Trees
- While log-structured indexes are gaining acceptance, B-tree is the most widely used indexing structure.
- B-trees is the standard index implementation for almost all relational databases and most non-relational databases.
- B-trees also keep key-value entires sorted by key, which allows quick value lookups and range queries.
- Log-structure indexes breaks databases down into variable length segments (several mbs or more), while B-tree breaks databases down into a fixed-size *blocks* or *pages* (4KB traditionally, but depends on underlying hardware).
- Each page can be identified by an address or location, which can be stored in another page on disk.
- A root page contains the full range of keys (or reference to pages containing the full range) and is where query start.
- A leaf page contains only individual keys, which contains the value inline or reference to where the values can be found.
- The branching factor is the number of references to a child page in one page of a B-tree.
- When changing values in B-trees, the page containing the value is looked up, modified, and written back to disk.
- When adding new values, first, the page whose range contains the key is looked up. If there is extra space in the page, the key-value entry is simply added, else, the page is split into two halves and the parent page is updated to account for the new file structure.
- The algorithm above ensures a B-tree with $$n$$ nodes is always balanced and has a depth of $$O(log n)$$.

#### Making B-Trees reliable
- When changing values or splitting pages, the B-tree overwrites data on disk. This is a risky operation. If anything crashes during an overwrite, the index could be corrupted.
- To make B-tree more resilient to such failures, a common solution is to include an *write-ahead-log* (WAL, or *redo log*), which every B-tree modification is first written to. In case of failure, this log can be used to restore the B-tree back to a consistent state.
- Care should also be taken when multiple threads may access the B-tree at the same time. An inconsistent state could be read during an update. Latches (lightweight locks) can be placed to protect the tree's integrity.

#### B-tree optimizations
- Just to mention a few optimizations:
  - Copy-on-write and atomic to remove the need to maintain a WAL for crashes
  - Key compression by storing essential information for acting as boundaries.
  - Arrange page on disk such that pages appear in sequential order on disk.
  - Additional pointers (such as left, right siblings) to allow efficient scanning of keys in order without jumping back to parents.
  - Fractal trees to reduce disk seeks.


### Comparing B-Trees and LSM-Trees

- Typically, B-Trees are faster for reads and LSM-Trees are faster for writes. The actual performance for a specific system would require benchmarking.

#### Advantages of LSM-trees
- Both B-Tree and LSM-tree indexes would require writing a piece of data to disk multiple times on write. This effect is known as write amplification. In write heavy applications, write amplification would directly impact performance.
- LSM-trees are typically able to sustain higher write throughput due to two main reasons: a lower write amplification and a sequential write (especially on magnetic hard drives).
- LSM-trees can be compressed better and have lower fragmentation due to rewriting of SSTables.
- Even on SSDs, LSM-trees are still advantages as it represents data more compactly and allows more read and write requests within the same bandwidth.

#### Downsides of LSM-trees
- The compaction process of LSM-trees can sometimes interfere with reads and writes, as reads and writes can be blocked by the compaction process on disk resources. Although the impact on average response time is usually small, this could greatly increase high-percentage response time.
- If write throughput is high and compaction is not configured correctly, it is not impossible that compaction can't keep up with incoming writes. Unmerged segments will then grow until disk space is all used. This effect has to be actively monitored.
- Since each key only appears once in a B-tree, B-trees are more attractive in databases when transaction isolation is implemented using locks on range of keys.

### Other Indexing Structures
- Secondary indexes can be created from a key-value index. The main difference between primary and secondary indexes is that secondary indexes are not unique. This can be solved two ways:
  - Make the value in the index a list of matching row identifiers.
  - Make each key unique by adding a row identifier to the secondary key.
- Both B-trees and log-structured indexes can be used as secondary indexes.

#### Storing values within the index
- In a key-value pair, the key is used to locate the entry and the value can be either the actual data or a reference to the storage location (known as a *heap* file). Using heap files is common for building multiple secondary indexes to reduce duplication.
- When updating values without changing keys, if the new value is no larger than old data, the value can be directly overwritten, and if the new value is larger, either all indexes needs to be updated or a forwarding pointer can be left in the old record.
- Sometimes, the extra hop to the heap file is too expensive for reads, and the indexed row is stored directly in the index. This is called a *clustered index*.
- A compromise between a non-clustered index and a clustered index is a *covering index* or *index with included columns*, where only some columns are stored within the index.

#### Multi-column indexes
- Multi-column indexes are created for querying rows using multiple columns of a table.
- The *concatenate index* is the most common multi-column index. This is done by simply concatenating fields together into one key. However the index is useless when a query is based on only one column.
- To index a two-dimensional location database (with latitude and longitude), we can use a space-filling curve and use a regular B-tree index. Specialized spatial index such as R-trees are also used.

#### Full-text search and fuzzy indexes
- Some applications require searching for a similar key. This can be done by *fuzzy indexes*.
- For example, Lucene allows searching for words within edit distance 1. In Lucene, the in-memory index is a finite state automaton over the characters in the keys (similar to a trie). This automaton can then be transformed into a Levenshtein automaton, which supports efficient search for words within a given distance.

#### Keeping everything in memory
- Some in-memory key-value stores, such as Memcached, are intended for caching only, where data is lost when the machine restarts. Some other in-memory databases aim for durability, which can be achieved with special hardware and saving change logs and snapshots to disk.
- Counterintuitively, in-memory databases are faster mainly because they avoid serialization and deserialization between in-memory structures and binaries, not because of the disk read and write time.
- In-memory databases could also provide data models that are hard to implement with disk-based indexes, such as priority queues, stacks.
- The anti-caching approach, where the least-recently-used data is dumped to disk when there is not enough memory and loaded back when queried, enables in-memory databases to support larger-than-memory databases. Yet the index would still have to fit into memory.
## Transaction Processing or Analytics?
### Data Warehousing
#### The divergence between OLTP databases and data warehouses
### Stars and Snowflakes: Schemas for Analytics
## Column-Oriented Storage
### Column Compression
#### Memory bandwidth and vectorized processing
### Sort Order in Column Storage
#### Several different sort orders
### Writing to Column-Oriented Storage
### Aggregation: Data Cubes and Materialized Views
## Summary



Summarized from [Designing Data-Intensive Applications](https://dataintensive.net/).